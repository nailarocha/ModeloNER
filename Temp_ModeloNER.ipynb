{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temp ModeloNER",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2jPoiG/oQeZXS8nxToKux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nailarocha/ModeloNER/blob/main/Temp_ModeloNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpsTp0iZ6Rh"
      },
      "source": [
        "1 - Importar bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "734LphMJZ3PC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import random\n",
        "import re\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from spacy.gold import GoldParse\n",
        "from spacy.scorer import Scorer\n",
        "from spacy import displacy\n",
        "from spacy.util import decaying\n",
        "from spacy.util import minibatch, compounding\n",
        "from thinc.neural.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuzuY5kHaFFB"
      },
      "source": [
        "2 - Pré Processamento da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vv6WATtaMFO"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTx2fI3qaQJq"
      },
      "source": [
        "pront = pd.read_csv('prontuarios.csv',\n",
        "                   sep=';',\n",
        "                   engine = 'python',\n",
        "                   encoding = 'latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_vYYJx7aQqJ"
      },
      "source": [
        "def clean_pront(texto):\n",
        "  texto = re.sub(r\"[^A-Za-z0-9.,+/]\",' ', texto) \n",
        "  texto = re.sub(r\" +\",' ', texto) \n",
        "  texto = re.sub(r\"(\\n)+\",' ', texto)\n",
        "  texto = BeautifulSoup(texto, 'lxml').get_text()\n",
        "  texto = re.sub(r\"@[A-Za-z0-9]+\",' ', texto)\n",
        "  texto = re.sub(r\"https?://[A-Za-z0-9./]+\",' ', texto)\n",
        "  return (texto)\n",
        "pront[\"evolucao\"] = [clean_pront(texto) for texto in pront.DSEVOLUCAO]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobvSmwsaS0p"
      },
      "source": [
        "texto = pront.evolucao\n",
        "def minusculo(texto):\n",
        "    if type(texto) == str:\n",
        "        return texto.lower()\n",
        "    else:\n",
        "        return [texto.lower() for texto in texto]\n",
        "print(minusculo(texto))\n",
        "pront[\"evolucao_min\"] = minusculo(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLDW7v-yaVMJ"
      },
      "source": [
        "3 - Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Ulr8SfaXR6"
      },
      "source": [
        "TRAIN_DATA = [\n",
        "              ('refere melhora miccao com combodart toma marevan e furosemida 6cp/dia pedido urina',\n",
        "               {'entities': [(26, 35, 'MEDICACAO'), (41, 48, 'MEDICACAO'), (51, 61, 'MEDICACAO'), (77, 82, 'EXAME')]}),\n",
        "              ('checo gasometria venosa ph 7,24 bic 16,1 k 3,79 lac 1,1 hb 13,7 conduta prescrevo bic 60ml',\n",
        "               {'entities': [(6, 23, 'EXAME'), (82, 85, 'MEDICACAO')\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBL4MChmamJJ"
      },
      "source": [
        "TEST_DATA = [\n",
        "              ('atendimento psa qp dor de ouvido ha 2 dias hpma dor ha 1 dia em ouvido esquerdo, hd otite aguda',\n",
        "               {'entities': [(19, 32, 'SINTOMA'), (48, 51, 'SINTOMA'), (84, 95, 'DIAGNOSTICO')]})\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6w8M14navCx"
      },
      "source": [
        "def train_spacy(data,iterations):\n",
        "    TRAIN_DATA = data\n",
        "    # cria o modelo vazio com idioma português\n",
        "    nlp = spacy.blank('pt')\n",
        "    # adiciona o componente NER ao pipeline\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnhvZsR_PXhP"
      },
      "source": [
        "    # adiciona rótulos na base de treino\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baMVMYpoPe1M"
      },
      "source": [
        "    # desativa demais componentes do pipeline\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2W_szzdPg9L"
      },
      "source": [
        "    # inicia treinamento com pesos aleatórios\n",
        "        optimizer = nlp.begin_training()\n",
        "        dropout = decaying(0.6, 0.2, 1e-4)\n",
        "        for itn in range(iterations):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC-02V3ZPnsI"
      },
      "source": [
        "            batches = minibatch (TRAIN_DATA, size = compounding (4.0, 32.0, 1.001))\n",
        "            for batch in batches:\n",
        "                text, annotations =zip(*batch)\n",
        "    # atualiza o modelo com ajuste dos pesos\n",
        "                nlp.update(\n",
        "                    text, \n",
        "                    annotations,  \n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "    return nlp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkBHs2C3PsMe"
      },
      "source": [
        "    # treino do modelo com 35 iterações\n",
        "prdnlp = train_spacy(TRAIN_DATA, 35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si8jWl_ua6v6"
      },
      "source": [
        "    # salva o modelo\n",
        "%cd /.Modelo\n",
        "!pwd\n",
        "modelfile = \"Modelo\"\n",
        "prdnlp.to_disk(modelfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr2OeYl8bL-S"
      },
      "source": [
        "4 - Análise qualitativa do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VAxiUyJbH4i"
      },
      "source": [
        "def evaluate(modelfile, ACC):\n",
        "    scorer = Scorer()\n",
        "        for input_, annot in ACC:\n",
        "        doc_gold_text = modelfile.make_doc(input_)\n",
        "        gold = GoldParse(doc_gold_text, entities=annot)\n",
        "        pred_value = modelfile(input_)\n",
        "        scorer.score(pred_value, gold)\n",
        "    return scorer.scores\n",
        "modelfile = spacy.load('.Modelo') \n",
        "results = evaluate(modelfile, ACC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGmwA3h6bboB"
      },
      "source": [
        "# lista de entidades encontradas com cada rótulo\n",
        "def show_ents(doc):\n",
        "  if doc.ents:\n",
        "    for ent in doc.ents:\n",
        "      #print(ent.text + ' | ' + str(ent.start_char) + ' - ' + str(ent.end_char) + ' | ' + (ent.label_))\n",
        "      print(ent.text + ' | ' + (ent.label_)+ ';')\n",
        "    else:\n",
        "      print('Mais nenhuma entidade encontrada')\n",
        "doc = prdnlp(str(ACC))\n",
        "saida = show_ents(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mKbgpM3bd9q"
      },
      "source": [
        "# quantidade de entidades encontradas\n",
        "print('MEDICACAO: ' + str(len([ent for ent in doc.ents if ent.label_ == \"MEDICACAO\"])))\n",
        "print('CONDICAO: ' + str(len([ent for ent in doc.ents if ent.label_ == \"CONDICAO\"])))\n",
        "print('DIAGNOSTICO: ' + str(len([ent for ent in doc.ents if ent.label_ == \"DIAGNOSTICO\"])))\n",
        "print('SINTOMA: ' + str(len([ent for ent in doc.ents if ent.label_ == \"SINTOMA\"])))\n",
        "print('TRATAMENTO: ' + str(len([ent for ent in doc.ents if ent.label_ == \"TRATAMENTO\"])))\n",
        "print('EXAME: ' + str(len([ent for ent in doc.ents if ent.label_ == \"EXAME\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G25bFulEbgKj"
      },
      "source": [
        "# análise de 1 registro\n",
        "test_text = \"PS mae refere que crianca foi picada por inseto hoje\"\n",
        "doc = prdnlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "# exibição gráfica das entidades na frase\n",
        "displacy.render(doc,style='ent',jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTSH4y3jb3Ru"
      },
      "source": [
        "5 - Pós-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBqwCHwb7Ug"
      },
      "source": [
        "# Adicionar colunas na base\n",
        "pront[\"SINTOMA\"]=\"\"\n",
        "pront[\"DIAGNOSTICO\"]=\"\"\n",
        "pront[\"MEDICACAO\"]=\"\"\n",
        "pront[\"EXAME\"]=\"\"\n",
        "pront[\"CONDICAO\"]=\"\"\n",
        "pront[\"TRATAMENTO\"]=\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf08LaKNcMyV"
      },
      "source": [
        "# Lista para armazenar o nome dos medicamentos\n",
        "MEDICACAO=[]\n",
        "# Anexar entidades que tenham o rótulo 'MEDICACAO' à lista\n",
        "for i in range(0,30000):\n",
        "  test_text = pront[\"DSEVOLUCAO\"][i]\n",
        "  doc = prdnlp(test_text)\n",
        "  for entity in doc.ents:\n",
        "    if entity.label_=='MEDICACAO':\n",
        "      MEDICACAO.append(entity.text)\n",
        "  pront.medicacao_ext[i] = MEDICACAO\n",
        "  MEDICACAO=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-FxxMDKcbln"
      },
      "source": [
        "# Selecionar apenas prontuários com menção de algum medicamento e criar lista de tags de medicamentos (removendo duplicados)\n",
        "pront_MEDICACAO = pront[pront['MEDICACAO'].notnull()]\n",
        "pront_MEDICACAO.MEDICACAO.unique()\n",
        "lista_de_tags = list()\n",
        "for tags in pront_MEDICACAO.MEDICACAO.unique():\n",
        "    for tag in tags.split(','):\n",
        "        if tag not in lista_de_tags:\n",
        "            lista_de_tags.append(tag)\n",
        "lista_de_tags = [elem.lstrip() for elem in lista_de_tags]\n",
        "print(lista_de_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TI90iGvcp3a"
      },
      "source": [
        "# Função para classificação binária (paciente consome (1) ou não (0) determinado medicamento)\n",
        "def nova_coluna(lista_tags, dataframe, nome_tags):\n",
        "    for tag in lista_tags:\n",
        "        coluna = list()\n",
        "        for linha_tag in dataframe[nome_tags]:\n",
        "            if tag in linha_tag:\n",
        "                coluna.append(1)\n",
        "            else:\n",
        "                coluna.append(0)\n",
        "        dataframe[tag] = coluna\n",
        "nova_coluna(lista_de_tags, pront_MEDICACAO, \"MEDICACAO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQS9Hhhb-58"
      },
      "source": [
        "# Instalando Pacotes\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"cluster\")\n",
        "install.packages(\"ggplot2\")\n",
        "library(dplyr)\n",
        "library(cluster) \n",
        "library(ggplot2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRDSe_7vcCJs"
      },
      "source": [
        "# Transformação das variáveis em categóricas e numérica\n",
        "med <- med %>% mutate_if(is.numeric,as.factor)\n",
        "med$IDADE=as.numeric(med$IDADE)\n",
        "str(med)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0EWoERcFIU"
      },
      "source": [
        "# Cálculo da distância de Gower\n",
        "gower_dist <- daisy(med,\n",
        "                    metric = \"gower\",\n",
        "                    type = list(logratio = 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSiJ-dGcK_0"
      },
      "source": [
        "# Cálculo do silhouette width com método PAM\n",
        "sil_width <- c(NA)\n",
        "for(i in 2:10){\n",
        "  pam_fit <- pam(gower_dist,\n",
        "                 diss = TRUE,\n",
        "                 k = i)\n",
        "  sil_width[i] <- pam_fit$silinfo$avg.width\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drciH-ZZcNw9"
      },
      "source": [
        "# Gráfico sihouette width (número de clusters)\n",
        "plot(1:10, sil_width,\n",
        "     xlab = \"Number of clusters\",\n",
        "     ylab = \"Silhouette Width\")\n",
        "lines(1:10, sil_width)\n",
        "pam_fit <- pam(gower_dist, diss = TRUE, k = 4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}